[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "A River’s History Visualized\n\n\n\n\n\n\nVisualization\n\n\nDEM\n\n\nXarray\n\n\nGeoPandas\n\n\nPython\n\n\n\nVisualizing the meanderings of the Snake River in Grand Teton National Park using a relative elevation model\n\n\n\n\n\nNov 3, 2024\n\n\nColin Hill\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nOct 2, 2024\n\n\nColin Hill\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "scratch.html",
    "href": "scratch.html",
    "title": "Colin Hill",
    "section": "",
    "text": "categories: [Visualization, DEM, Cloud Native Data, Xarray, Dask, GeoPandas, STAC, Python]\n\n\n\n# Mississippi River\n# bbox = [-91.48, 32.39, -90.78, 33.34] # WSG84 coordinates, WSEN\n\n# # Quinault River\n# bbox = [-124.075, 47.35, -123.87, 47.47] # WSG84 coordinates, WSEN\n\n\nimport geopandas as gpd\nimport shapely\n\nWe can retrieve the river’s geometry from a USGS dataset Mainstem Rivers of the Conterminous United States hosted on GeoConnex. We’ll use the mainstem collection and search for our river of interest using the name_at_outlet property. This can return a json which we can easily manipulate using Geopandas.\n\nimport requests\n\nname_at_outlet = \"Mississippi River\"\nname_at_outlet = \"Quinault River\"\n# name_at_outlet = \"Wynoochee River\"\nname_at_outlet = \"Snake River\"\n\nurl = \"https://reference.geoconnex.us/collections/mainstems/items\"\nres = requests.get(url, params={\"f\": \"json\", \"name_at_outlet\": name_at_outlet})\ndata = res.json()\n\n\n\n# Create GeoDataframe from the featureCollection with CRS\ngdf_river = gpd.GeoDataFrame.from_features(data).set_crs('EPSG:4326')\n\n# Verify there is only 1 geometry\n# assert(len(gdf_river)) == 1\n\n\n# Clip geometry to our bounding box\ngdf_river = gdf_river.clip(gdf_bbox)\n\nNow we need to retrieve a Digital Elevation Model (DEM) data layer. For this we can use the Copernicus Digital Elevation Model available from the AWS open data catalogue. We can use the free STAC API Earth Search from Element84 to find the data, and pystac and odc tools to download only the data we need.\n\nfrom pystac_client import Client\nimport odc.stac\nimport os\nimport rasterio\nimport geopandas as gpd\n\n\n# reference https://stacspec.org/en/tutorials/access-sentinel-2-data-aws/\n\n\n# catalog = Client.open(\"https://portal.opentopography.org/stac/catalog.json\")\n# # https://portal.opentopography.org//stac//WY08_SnakeRiver/raster_catalog.json\n\n\n# query = catalog.search(\n#     collections=\"Snake River, Wyoming\",\n#     # bbox=bbox,\n#     limit=100\n# )\n\n\n# collection_id = 'cop-dem-glo-30'\n\n# # Query the catalogue for data from the collection within the bbox\n# query = catalog.search(\n#     collections=[collection_id],\n#     bbox=bbox,\n#     limit=100\n# )\n\n# items = list(query.items())\n# print(f\"Found: {len(items):d} items\")\n\n\n# Disable AWS sign-in\n# os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n\nimport planetary_computer\n\n\n# Open STAC catalogue\ncatalog = Client.open(\n    \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n    modifier=planetary_computer.sign_inplace,\n)\n\n\n# Query the catalogue for data from the collection within the bbox\nquery = catalog.search(\n    collections='3dep-seamless',\n    bbox=bbox,\n    query=[\"gsd==10\"], # Get data at 10m resolution\n    limit=100,\n)\n\n\nitems = list(query.items())\nprint(f\"Found: {len(items):d} items\")\n\n\nds = odc.stac.load(\n    items,\n    bands=None,\n    crs=\"EPSG:32610\",\n    resolution=10,\n    chunks={}, \n)\n\n\nds\n\n\n# # Disable AWS sign-in\n# os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n\n# # Open STAC catalogue\n# catalog = Client.open(\"https://earth-search.aws.element84.com/v1\")\n\n# # The DEM data collection\n# collection_id = 'cop-dem-glo-30'\n\n# # Query the catalogue for data from the collection within the bbox\n# query = catalog.search(\n#     collections=[collection_id],\n#     bbox=bbox,\n#     limit=100\n# )\n\n# items = list(query.items())\n# print(f\"Found: {len(items):d} items\")\n\n\n\n# # Convert STAC items into a GeoJSON FeatureCollection\n# stac_json = query.item_collection_as_dict()\n\nWe can now construct a Dask backed dataset in Xarray using the odc.stac.load function, where we specify chunks={} to enable Dask lazy-loading and auto chunking of the data.\n\n# ds = odc.stac.load(\n#     items,\n#     bands=None,\n#     crs=\"EPSG:3857\",\n#     resolution=30,\n#     chunks={}, \n# )\n\n\n# The time coorcinate is not relevant so we can remove it\ndem = ds['data'].drop_vars('time').squeeze()\n\nNow we can crop the extent of the data to our bounding box. We need to be careful here as the DEM is in a different coordinate system, and we can use odc.geo.xr extensions to handle the conversion\n\nimport odc.geo\n\n# Create a geopolygon with the original bbox coordinates and CRS, then convert to our data CRS\n# geopolygon = odc.geo.Geometry(shapely.box(*bbox), crs='EPSG:4326').to_crs(\"EPSG:3857\")\ngeopolygon = odc.geo.Geometry(shapely.box(*bbox), crs='EPSG:4326').to_crs(\"EPSG:32610\")\n\n\n# Crop the data\ndem = dem.odc.crop(geopolygon)\n\n\nprint(f'DataArray is {dem.nbytes / (1024**2):.2f}MB')\n\nNow the data is fairly small and ready to be loaded into memory\n\n%%time\ndem = dem.compute()\n\n\n# dem.plot(\n#     vmin=2000, vmax=2060, \n#     figsize=(12,8)\n#     );\n\n\n# slope = xrspatial.slope(dem)\n\n\n# curvature = xrspatial.curvature(dem)\n\n\n# slope.plot(vmin=-1, vmax=1);\n\n\n# # np.where(np.logical_and(\n# (np.abs(slope) &lt; 0.5).plot();\n\n\n# curvature.plot(vmin=-5, vmax=5);\n\nNow we can compute the REM. For this we’ll need to: 1. Calculate the elevation of the river along its path (from the DEM data) 2. Interpolate this to create a 2-D elevation raster 3. Subtract this interpolated elevation raster from the DEM\n\nimport xarray as xr\nimport numpy as np\nfrom scipy.spatial import KDTree\n\n\n# _gdf_river = gdf_river.to_crs(\"EPSG:32610\")\n\n\nriver_geom = gdf_river.to_crs(\"EPSG:32610\").iloc[0].geometry\n\n\nriver_geom = shapely.line_merge(river_geom)\n\n\nimport scipy#.interpolate\n\n\nx, y = shapely.get_coordinates(river_geom).T\nkonts = np.hypot(np.diff(x), np.diff(y)).cumsum()\nkonts = np.insert(konts, 0, 0)\nkonts /= konts[-1]\n\nsmoothing = None\nspl_x = scipy.interpolate.UnivariateSpline(konts, x, k=3, s=smoothing)\nspl_y = scipy.interpolate.UnivariateSpline(konts, y, k=3, s=smoothing)\n_npts = 5 * len(x)\nkonts = np.linspace(0, 1, _npts)\n\n\nriver_geom_smooth = shapely.LineString(np.c_[spl_x(konts), spl_y(konts)])\n\n\nxs, ys = river_geom_smooth.xy\nxs, ys = xr.DataArray(xs, dims='z'), xr.DataArray(ys, dims='z')\n\n# Take nearest elevation to those coordinates\nriver_elevation = dem.interp(x=xs, y=ys, method='linear').dropna(dim='z')\n\n\n# River geometry\n# river_geom = gdf_river.to_crs(\"EPSG:32610\").iloc[0].geometry\n\n\n\n# # Extract coordinates as an xr.DataArray\n# xs, ys = river_geom.xy\n# xs, ys = xr.DataArray(xs, dims='z'), xr.DataArray(ys, dims='z')\n\n# # Take nearest elevation to those coordinates\n# river_elevation = dem.interp(x=xs, y=ys, method='nearest').dropna(dim='z')\n\nTo mitigate artifacts arising from the river geometry and DEM not matching (due to natural change over time), we can ensure that the river elevation decreases or stays constant between pixels\n\nriver_elevation.plot(figsize=(4, 2));\n\n\n# Ensure the array is non-increasing\nriver_elevation.values = np.minimum.accumulate(river_elevation.values)\n\n\nriver_elevation.plot(figsize=(4, 2));\n\n\n# Interpolate the river elevation using Inverse Distance Weighted interpolation\nriver_elevation_coords = np.column_stack((river_elevation.x, river_elevation.y))\n\nkdt = KDTree(river_elevation_coords)\ndem_grid = np.dstack(np.meshgrid(dem.x, dem.y)).reshape(-1, 2)\n\n\nk = 50\ndistances, indices = kdt.query(dem_grid, k=k)\nweights = np.reciprocal(distances)\nweights = weights / weights.sum(axis=1, keepdims=True)\nriver_elevation_interpolated = weights * river_elevation.to_numpy()[indices]\nriver_elevation_interpolated = river_elevation_interpolated.sum(axis=1).reshape((dem.sizes[\"y\"], dem.sizes[\"x\"]))\nriver_elevation_interpolated = xr.DataArray(river_elevation_interpolated, dims=(\"y\", \"x\"), coords={\"x\": dem.x, \"y\": dem.y})\n\n\nriver_elevation_interpolated.plot();\n\nFinally calculate the relative elevation\n\nrem = dem - river_elevation_interpolated\n\n\nrem.min().values, rem.max().values\n\n\nrem = rem - rem.min()\n\n\nimport matplotlib as mpl\n\n\nrem.plot(\n    # vmin=-3.3, vmax=12,\n    figsize=(12,8), cmap=\"YlGnBu\",\n    norm=mpl.colors.LogNorm(vmin=2, vmax=25)\n      );\n\n\nfrom datashader.transfer_functions import shade, stack\nimport xrspatial\nfrom datashader import Canvas\nfrom datashader.utils import export_image\n\n\nimg = stack(\n    shade(xrspatial.hillshade(dem, angle_altitude=10, azimuth=90), cmap=[\"black\", \"white\"], how=\"linear\", alpha=200),\n    shade(rem, cmap=mpl.colormaps['YlGnBu'],\n          span=[0, 15],\n          how=\"linear\",\n        #   how=\"log\",\n          alpha=200\n          )\n)[::-1]\n# Swap x-y\n# # export_image(img, \"rem_image\", background=\"black\", export_path=\".\")\nimg"
  },
  {
    "objectID": "posts/relative_elevation_model/index.html",
    "href": "posts/relative_elevation_model/index.html",
    "title": "A River’s History Visualized",
    "section": "",
    "text": "A wonderful aspect of geospatial data is that it’s both beautiful and informative. In this post I look at the migration of the Snake River in Grand Teton National Park, USA over time by creating a relative elevation model (REM). This takes a digital elevation model (DEM) and de-trends the baseline elevation so it follows the water’s surface. By doing so, we can clearly see the migration of the river’s channels and the associated features such as oxbow lakes, meander scars and terraces.\nThis post was inspired by this blog post and this notebook, and makes use of the HyRiver suite of package for data access: PyNHD for river flowlines and Py3DEP for a high resolution DEM.\n\n# Define AOI bounding box\n\n# Snake River, Grand Teton National Park\nbbox = [-110.583466, 43.790715, -110.509222, 43.848585] # WSG84 coordinates, WSEN\n\nFor the first step we will retrieve the river’s path. We can retrieve the river’s flowline (geometry) from USGS data which is easily accessible using the PyNHD package\n\n\nCode\nimport pynhd\nimport py3dep\nimport geopandas as gpd\nimport shapely\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nimport pyproj\nimport numpy as np\nimport pygeoutils\nimport xarray as xr\nfrom scipy.spatial import KDTree\n\n\n\n# Connect to service \nwater_data = pynhd.WaterData(\"nhdflowline_network\")\n\n# Get flowlines within bounding box\nflowlines = water_data.bybox(bbox)\n\n\n# This returns a GeoDataFrame\nflowlines.head(2)\n\n\n\n\n\n\n\n\ngeometry\ncomid\nfdate\nresolution\ngnis_id\ngnis_name\nlengthkm\nreachcode\nflowdir\nwbareacomi\n...\nqc_12\nvc_12\nqe_12\nve_12\nlakefract\nsurfarea\nrareahload\nrpuid\nvpuid\nenabled\n\n\n\n\n0\nMULTILINESTRING Z ((-110.54139 43.79185 0, -11...\n23123173\n2005-07-21T04:00:00Z\nMedium\n\n\n3.651\n17040101000094\nWith Digitized\n0\n...\n0.132\n0.53390\n0.132\n0.53390\nNaN\nNaN\nNaN\n17a\n17\n1\n\n\n1\nMULTILINESTRING Z ((-110.54022 43.79151 0, -11...\n23123175\n2001-02-07T05:00:00Z\nMedium\n1603229\nSpread Creek\n0.102\n17040101000095\nWith Digitized\n0\n...\n68.385\n1.23836\n68.385\n1.23836\nNaN\nNaN\nNaN\n17a\n17\n1\n\n\n\n\n2 rows × 138 columns\n\n\n\nWe want to keep the main stream only, which in this case we can easily do by filtering on the gnis_name\n\nflowline = flowlines.loc[flowlines['gnis_name'].eq('Snake River')]\n\n\n# Plot flowlines and bounding box\n\n# Create GeoDataframe with bounding box\ngdf_bbox = gpd.GeoDataFrame(data={'geometry': shapely.box(*bbox)}, index=[0], crs='EPSG:4326')\nm = flowlines.explore(color='blue')\nflowline.explore(color='red', m=m)\ngdf_bbox.explore(color=\"black\", style_kwds={\"fillColor\": \"None\"}, m=m)\nm\n\nMake this Notebook Trusted to load map: File -&gt; Trust Notebook\n\n\nFor the next step, we’ll retrieve a DEM for the region. For this we can use the Py3DEP package which gives us easy access to the USDA 3DEP database\n\n# Check which resolutions are available in our AOI\ndem_resolutions = py3dep.check_3dep_availability(bbox)\ndem_resolutions\n\n{'1m': True,\n '3m': True,\n '5m': False,\n '10m': True,\n '30m': True,\n '60m': False,\n 'topobathy': False}\n\n\nDEM data is available at up to 1m resolution, however we’ll use 3m to save time and computation. We can simply use py3dep.get_dem to download data for our AOI and chosen resolution and return an xarray.DataArray\n\ndem = py3dep.get_dem(bbox, resolution=3, crs=flowline.crs)\n\n\n# Plot DEM with river overlayed\nfig, ax = plt.subplots(figsize=(6, 4))\ndem.plot(ax=ax, robust=True);\nflowline.plot(ax=ax, color=\"r\");\n\n\n\n\n\n\n\n\nTo de-trend the DEM, we need to find the elevation profile along the river’s flowline. While py3dep.elevation_profile provides this functionality, it uses the 10m DEM, and as we already have 3m data we can use it instead with a little extra work.\n\n# First combine all geometries to a single MultiLineString\nline = shapely.union_all(flowline.line_merge())\n\n# Smooth the line to 3m spacing and extract height from the DEM\n\n# Reproject to meters\nproject = pyproj.Transformer.from_crs(flowline.crs, 5070, always_xy=True).transform\nline_5070 = shapely.ops.transform(project, line)\n\n# Smooth line\nspacing = 3 # 3m spacing\nnpts = int(np.ceil(line_5070.length / spacing))\nline_5070_smooth = pygeoutils.smooth_linestring(line_5070, 0.1, npts)\n\n# Reproject back to original crs\nproject = pyproj.Transformer.from_crs(5070, flowline.crs, always_xy=True).transform\nline_smooth = shapely.ops.transform(project, line_5070_smooth)\n\n# Extract elevation from DEM\nxs, ys = line_smooth.xy\nxs, ys = xr.DataArray(xs, dims='distance'), xr.DataArray(ys, dims='distance')\nriver_dem = dem.interp(x=xs, y=ys, method='nearest').dropna(dim='distance')\n\nTo mitigate artifacts arising from the river geometry and DEM not matching (due to natural change over time), we can ensure that the river elevation decreases or stays constant between pixels\n\n# Ensure the elevation is non-increasing\nriver_dem.values = np.minimum.accumulate(river_dem.values)\n\n\nriver_dem.plot(figsize=(4, 2));\n\n\n\n\n\n\n\n\nNow we need to interpolate the height of the river over the entire AOI. We can do this using the inverse distance weighting (IDW) method.\n\n\nCode\ndef idw(da_in: xr.DataArray, da_out: xr.DataArray, k: int = 10, n: float = 1) -&gt; xr.DataArray:\n    \"\"\"\n    Inverse distance weighted interpolation\n    \n    Args:\n        da_in: Input data to interpolate\n        da_out: Output grid\n        k: Number of nearest points to include\n        n: Exponent of the weighting\n\n    Returns:\n        Interpolated data\n    \"\"\"\n    coords = np.column_stack((da_in.x, da_in.y))\n    kdt = KDTree(coords)\n\n    grid = np.dstack(np.meshgrid(da_out.x, da_out.y)).reshape(-1, 2)\n    distances, indices = kdt.query(grid, k=k)\n\n    weights = np.power(np.reciprocal(distances), n)\n    weights = weights / weights.sum(axis=1, keepdims=True)\n    interp = weights * da_in.to_numpy()[indices]\n    interp = interp.sum(axis=1).reshape((da_out.sizes[\"y\"], da_out.sizes[\"x\"]))\n    interp = xr.DataArray(interp, dims=(\"y\", \"x\"), coords={\"x\": da_out.x, \"y\": da_out.y})\n    return interp\n\n\n\nriver_dem_interp = idw(river_dem, dem, k=200, n=0.5)\n\n\nriver_dem_interp.plot(figsize=(6, 4));\n\n\n\n\n\n\n\n\nFinally, we can compute the REM from the river’s elevation profile and the DEM\n\nrem = dem - river_dem_interp\n\n\n# To simplify plotting, set minimum to zero\nrem = rem - rem.min()\n\n\nax = rem.plot.imshow(figsize=(12,8), cmap=\"YlGnBu\", norm=mpl.colors.LogNorm(vmin=1, vmax=10), add_colorbar=False, add_labels=False);\nax.axes.set_aspect('equal');\nax.axes.axis('off');\nplt.savefig(\"rem.png\", bbox_inches='tight', pad_inches=0, dpi=100)\n\n\n\n\n\n\n\n\nWe can clearly see the complex pattern of different paths the river has taken over the years, and the extent of the floodplains."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome my blog. This will be a space to jot down ideas, experiments, and things I find interesting. I love having a nice visualization to go along with code and analysis, so to kick off I’ll just include this incredible image of the Yukon Delta in Alaska.\n\n\n\nFalse-color image of the Yukon Delta, Alaska, USA (source)\n\n\n\nTopics\nSome major themes will be:\n\nRemote sensing\nEnvironment\nClimate\nWeather\nDemographics\nGeospatial data\n\nAs well as software and tools such as:\n\nPython\nJulia\nMachine Learning / Artificial intelligence\nCloud native data\nGeospatial software\n\n\n\nTech stack\nI’m building this website with Quarto and Pixi."
  },
  {
    "objectID": "about/about.html",
    "href": "about/about.html",
    "title": "Dr. Colin Hill",
    "section": "",
    "text": "I’m a data scientist and physicist working at the intersection of remote sensing, climate, environment and machine learning.\nI’ve worked across diverse domains ranging from stellar astrophysics to weather forecasts, from climate data to crops, GHG emissions and soil carbon sequestration. I enjoy working on challenging and impactful problems, and a consistent focus has been creating data-driven insights from sensors using physical principles combined with statistical and machine learning approaches."
  },
  {
    "objectID": "about/about.html#bio",
    "href": "about/about.html#bio",
    "title": "Dr. Colin Hill",
    "section": "",
    "text": "I’m a data scientist and physicist working at the intersection of remote sensing, climate, environment and machine learning.\nI’ve worked across diverse domains ranging from stellar astrophysics to weather forecasts, from climate data to crops, GHG emissions and soil carbon sequestration. I enjoy working on challenging and impactful problems, and a consistent focus has been creating data-driven insights from sensors using physical principles combined with statistical and machine learning approaches."
  },
  {
    "objectID": "about/about.html#experience",
    "href": "about/about.html#experience",
    "title": "Dr. Colin Hill",
    "section": "Experience",
    "text": "Experience\nRegrow Ag | 2022-2024\nSenior Data Scientist\nTechnical Lead\nWeatherForce | 2019-2021\nSenior Data Scientist\nInstitut de Recherche en Astrophysique et Planétologie | 2016-2019\nPostdoctoral Research Scientist (Astrophysics)"
  },
  {
    "objectID": "about/about.html#education",
    "href": "about/about.html#education",
    "title": "Dr. Colin Hill",
    "section": "Education",
    "text": "Education\nPh.D. Astrophysics | 2012-2015\nQueen’s University Belfast, UK\nM.Sci. Physics | 2008-2012\nQueen’s University Belfast, UK"
  }
]